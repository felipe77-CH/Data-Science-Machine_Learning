{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capitulo 9: Clases imbalanceadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIbliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from itertools import zip_longest\n",
    "from tabulate import tabulate\n",
    "import pdfkit\n",
    "import seaborn as sns\n",
    "from itertools import zip_longest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, cross_val_score  \n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn import impute\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import metrics\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.tree as tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.neighbors as neighbors\n",
    "import sklearn.naive_bayes as nb\n",
    "import sklearn.svm as svm\n",
    "import sklearn.ensemble as ensemble\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from yellowbrick.features import (JointPlotVisualizer,)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Si está clasificando datos y las clases no están relativamente equilibradas en tamaño, el sesgo hacia clases más populares puede llevar en su modelo. Por ejemplo, si tienes 1 caso positivo y 99 casos negativos, puede obtener una precisión del 99% simplemente clasificando todo como negativo. Hay varias opciones para abordar las clases desequilibradas.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilice la métrica diferente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una sugerencia es utilizar una medida distinta a la precisión (AUC es una buena elección) para calibrar modelos. La precisión y la recuperación son También mejores opciones cuando los tamaños de destino son diferentes. Sin embargo,También hay otras opciones a considerar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos y conjuntos basados ​​en árboles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos basados ​​en árboles pueden funcionar mejor según la distribución de la clase más pequeña. Si tienden a estar agrupados,se puede clasificar más fácilmente. Los métodos conjuntos pueden ayudar aún más a sacar a la minoría clases. El embolsado y el impulso son opciones que se encuentran en los modelos de árbol.como bosques aleatorios y aumento de gradiente extremo (XGBoost)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalize Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Muchos modelos de clasificación de scikit-learn respaldan la parámetro class_weight. Configurarlo en 'equilibrado' intentará regularizar las clases minoritarias e incentivar el modelo para clasificar ellos correctamente. Alternativamente, puede buscar en la cuadrícula y especificar las opciones de peso pasando una clase de mapeo de diccionario al peso (dar mayor peso a las clases más pequeñas). La biblioteca XGBoost tiene el parámetro max_delta_step, que Se puede configurar de 1 a 10 para que el paso de actualización sea más conservador.También tiene el parámetro scale_pos_weight que establece el proporción de muestras negativas a positivas (para clases binarias). También, eval_metric debe establecerse en 'auc' en lugar del valor predeterminado valor de 'error' para la clasificación. El modelo KNN tiene un parámetro de ponderación que puede sesgar a los vecinos. que están más cerca. Si las muestras de clases minoritarias están cerca juntos, establecer este parámetro en 'distancia' puede mejorar actuación.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importacion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta completa al archivo CSV\n",
    "file_path = 'C:/Users/felip/OneDrive/Documentos/Python/Codigos/Ciencia_Datos/Datos_titanic_CSV/titanic3.csv'\n",
    "# Importar la base de datos\n",
    "df = pd.read_csv(file_path)\n",
    "X= df\n",
    "# Puedes imprimir el DataFrame si lo deseas\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweak_titanic(df):\n",
    "    df = df.drop(columns=[\n",
    "        \"name\",\n",
    "        \"ticket\",\n",
    "        \"home.dest\",\n",
    "        \"boat\",\n",
    "        \"body\",\n",
    "        \"cabin\"\n",
    "    ]).pipe(pd.get_dummies, drop_first=True)\n",
    "    return df\n",
    "\n",
    "ti_df = tweak_titanic(df)\n",
    "#print(ti_df)\n",
    "def get_train_test_X_y(df, y_col, size=0.3, std_cols=None):\n",
    "    #Obtencion del conjunto de prueba y entreanamiento\n",
    "    y = df[y_col]\n",
    "    X = df.drop(columns=y_col)\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=size, random_state=42)\n",
    "    cols = X.columns\n",
    "    num_cols = [\"pclass\", \"age\", \"sibsp\", \"parch\", \"fare\"]\n",
    "    #Imputacion de los valores faltantes \n",
    "    fi = impute.IterativeImputer()\n",
    "    X_train.loc[:, num_cols] = fi.fit_transform(X_train[num_cols])\n",
    "    X_test.loc[:, num_cols] = fi.transform(X_test[num_cols])\n",
    "    #Estandarizacion de los valores \n",
    "    if std_cols:\n",
    "        std = preprocessing.StandardScaler()\n",
    "        X_train.loc[:, std_cols] = std.fit_transform(X_train[std_cols])\n",
    "        X_test.loc[:, std_cols] = std.transform(X_test[std_cols])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "ti_df = tweak_titanic(df)\n",
    "std_cols = \"pclass,age,sibsp,fare\".split(\",\")\n",
    "X_train, X_test, y_train, y_test = get_train_test_X_y(ti_df, \"survived\", std_cols=std_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minoría de muestreo superior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "mask = df.survived == 1\n",
    "surv_df = df[mask]\n",
    "death_df = df[~mask]\n",
    "df_upsample = resample(\n",
    "    surv_df,\n",
    "    replace=True,\n",
    "    n_samples=len(death_df),\n",
    "    random_state=42,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([death_df, df_upsample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived\n",
       "0    809\n",
       "1    809\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.survived.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*También podemos usar la biblioteca de aprendizaje desequilibrado para muestrear aleatoriamente con reemplazo:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived\n",
       "1    809\n",
       "0    809\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "y = df[\"survived\"]\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "pd.Series(y_ros).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Minority Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*La biblioteca de aprendizaje desequilibrado también puede generar nuevas muestras de clases minoritarias con el sobremuestreo de minorías sintéticas Técnica (SMOTE) y Sintética Adaptativa (ADASYN)algoritmos de enfoque de muestreo. SMOTE funciona eligiendo uno de sus k vecinos más cercanos, conectando una línea a uno de ellos, y eligiendo un punto a lo largo de esa línea. ADASYN es similar a SMOTE, pero genera más muestras de aquellas que están más difícil de aprender. Las clases en imbanced-learn se nombran over_sampling.SMOTE y over_sampling.ADASYN.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling Majority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Otro método para equilibrar las clases es reducir la muestra de la mayoría. clases. Aquí hay un ejemplo de sklearn:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived\n",
       "1    500\n",
       "0    500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "mask = df.survived == 1\n",
    "surv_df = df[mask]\n",
    "death_df = df[~mask]\n",
    "df_downsample = resample(\n",
    "    death_df,\n",
    "    replace=False,\n",
    "    n_samples=len(surv_df),\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "df3 = pd.concat([surv_df, df_downsample])\n",
    "df3.survived.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No utilice el reemplazo al reducir la resolución*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*La biblioteca imbalanced-learn también implementa varios algoritmos de reducción de muestreo:*\n",
    "\n",
    "- *ClusterCentroids*\n",
    "  *Esta clase utiliza K-means para sintetizar datos con los centroides.*\n",
    "\n",
    "- *RandomUnderSampler*\n",
    "  *Esta clase selecciona muestras al azar.*\n",
    "\n",
    "- *NearMiss*\n",
    "  *Esta clase utiliza vecinos más cercanos para reducir el muestreo.*\n",
    "\n",
    "- *TomekLink*\n",
    "  *Esta clase reduce el muestreo eliminando muestras que están cerca entre sí.*\n",
    "\n",
    "- *EditedNearestNeighbours*\n",
    "  *Esta clase elimina muestras que tienen vecinos que no pertenecen a la mayoría o todos de la misma clase.*\n",
    "\n",
    "- *RepeatedNearestNeighbours*\n",
    "  *Esta clase llama repetidamente a EditedNearestNeighbours.*\n",
    "\n",
    "- *AllKNN*\n",
    "  *Esta clase es similar, pero aumenta el número de vecinos más cercanos durante las iteraciones de reducción de muestreo.*\n",
    "\n",
    "- *CondensedNearestNeighbour*\n",
    "  *Esta clase elige una muestra de la clase a reducir,*\n",
    "  *luego itera a través de las otras muestras de la clase,*\n",
    "  *y si KNN no clasifica erróneamente, agrega esa muestra.*\n",
    "\n",
    "- *OneSidedSelection*\n",
    "  *Esta clase elimina muestras ruidosas.*\n",
    "\n",
    "- *NeighbourhoodCleaningRule*\n",
    "  *Esta clase utiliza los resultados de EditedNearestNeighbours y*\n",
    "  *aplica KNN a esos resultados.*\n",
    "\n",
    "- *InstanceHardnessThreshold*\n",
    "  *Esta clase entrena un modelo y luego elimina muestras con*\n",
    "  *probabilidades bajas.*\n",
    "\n",
    "*Todos estos clases admiten el método .fit_sample.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsampling Then Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The imbalanced-learn library implements SMOTEENN and SMOTE Tomek, which both upsample and then apply downsampling to clean up the data.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
